<Reference>
Project context: @_bmad-output/planning-artifacts/product-brief.md, @_bmad-output/planning-artifacts/project-context.md, _bmad-output/planning-artifacts/prd/index.md, _bmad-output/planning-artifacts/architecture/index.md, _bmad-output/planning-artifacts/epics/index.md

Implementation: _bmad-output/implementation-artifacts/

- Append all updates that should be referenced by QA to the end of CHANGELOG.md. Prepend with the result from running `Bash(date +"%y%m%d-%H:%M:%S")`
- Unrecognized changes: assume other agent; keep going; focus your changes. If it causes issues, stop + ask user.
- Offload simple / manual tasks to subagents and scripts. ie) offload 'manual' tasks and anything that doesn't require active thinking in the process. i18n is a great example.
- Read extra files iff necessary, BE HYPER context-efficient and offload any research / search / verification / exploration task to sub-agents by default. You are the consumer and implementor, not the researcher.
- Based on the difficulty of each task, assign opus / sonnet / haiku adaptively for subagents.
</Reference>

CRITICAL: Execute each step sequentially.

[TASKS]
STEP1: Use multiple subagents to scan the docs on what was implemented to understand user journeys and features that should be e2e tested.

STEP2: Based on the research, go through the project actual implementation using multiple subagents to get a plan on how to create the e2e tests. Note that they already exist so make sure there are no duplicates.

STEP3: Consolidate the information and use multiple subagents to create the e2e tests

STEP4: Use multiple subagents to verify the e2e tests with implementation expectations. Keep in mind if the implementation is off the tests SHOULD fail.

STEP5: Run the e2e tests, check the results and use multiple subagents to address ALL issues in parallel

STEP6: Repeat STEP5 until no issues

STEP7: Update CHANGELOG and provide a summary of the entire run.



Create a worktree, enter worktree, and implement 